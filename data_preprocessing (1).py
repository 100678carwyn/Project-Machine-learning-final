# -*- coding: utf-8 -*-
"""Data_preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19ziyaV-TWX6FR9Lz_SXhh7nrOrKu7Fd5

Nguyễn Thảo Quyên - 2351060031

Nguyễn Phạm Triệu Vỹ - 2351060042

# import data
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split

df = pd.read_csv("/content/drive/MyDrive/Ml off/data_cleaned (1).csv")

df.head()

df.shape

"""# Data Preprocessing"""

# xoá height và weight do tương quan cao với BMI, giúp model giảm overfit
target ='cardio'
df_base = df.drop(columns=['height','weight'])

df_base.to_csv("data_base.csv", index=False) # save data
print(df_base.shape)

"""# Feature engineering"""

df_fe = df.copy()

''' Giá trị cao → động mạch cứng → nguy cơ tim mạch tăng,
Giúp model học được mối quan hệ phi tuyến giữa huyết áp và nguy cơ bệnh tim.'''

df_fe["pulse_pressure"] = df_fe["ap_hi"] - df_fe["ap_lo"]

'''Note:

MAP ≈ áp lực trung bình trong suốt chu kỳ tim

Quan trọng hơn chỉ số ap_hi/ap_lo riêng lẻ

Thường dùng trong y khoa để đánh giá tưới máu cơ quan

ML rationale:
Feature y học chuẩn → tăng khả năng tổng quát hóa (generalization).'''

df_fe["MAP"] = df_fe["ap_lo"] + df_fe["pulse_pressure"] / 3

'''Giúp model phân biệt rủi ro tăng dần theo mức BMI.'''
df_fe["BMI_class"] = pd.cut(
    df_fe["BMI"],
    bins=[0, 18.5, 25, 30, 100],
    labels=[0, 1, 2, 3],   # under, normal, over, obese
    right=False
).astype(int)

# Cờ tăng huyết áp
# Giúp các model cây (RF, XGBoost) split nhanh và hiệu quả.
df_fe["hypertension"] = (
    (df_fe["ap_hi"] >= 140) | (df_fe["ap_lo"] >= 90)
).astype(int)

# phân loại huyết áp
# Giảm nhiễu so với dùng 2 biến thô → học pattern ổn định hơn.
def bp_category(row):
    if row["ap_hi"] < 120 and row["ap_lo"] < 80:
        return 0  # normal
    elif 120 <= row["ap_hi"] < 130 and row["ap_lo"] < 80:
        return 1  # elevated
    elif 130 <= row["ap_hi"] < 140 or 80 <= row["ap_lo"] < 90:
        return 2  # stage 1
    else:
        return 3  # stage 2

df_fe["BP_class"] = df_fe.apply(bp_category, axis=1)

'''Đại diện nhóm metabolic syndrome

Kết hợp béo phì + đường huyết cao + cholesterol cao

Rủi ro rất cao cho bệnh tim mạch'''

df_fe["metabolic_risk"] = (
    (df_fe["BMI"] >= 30) &
    (df_fe["gluc"] >= 2) &
    (df_fe["cholesterol"] >= 2)
).astype(int)
# Feature tương tác (interaction feature) → model không cần tự học phép AND phức tạp.

df_fe.to_csv("data_fe.csv", index=False)

print("FE shape:", df_fe.shape)

"""## Train test data"""

from sklearn.model_selection import train_test_split

X_base = df_base.drop(columns=[target])
y = df_base[target]

X_fe = df_fe.drop(columns=[target])

X_train_base,X_test_base,y_train,y_test = train_test_split(X_base,y,test_size = 0.2, random_state= 42, stratify=y)

# Map FE theo index
X_train_fe = X_fe.loc[X_train_base.index]
X_test_fe  = X_fe.loc[X_test_base.index]

X_train_fe.head()

"""Các biến feature engineering như Pulse Pressure, MAP, BP Class và Hypertension được xây dựng trực tiếp từ các chỉ số huyết áp gốc (ap_hi, ap_lo), do đó có thể tồn tại mối tương quan cao giữa các biến.

Tuy nhiên, nghiên cứu này sử dụng các mô hình cây quyết định (Random Forest, XGBoost), là các mô hình không nhạy cảm với đa cộng tuyến, vì chúng không ước lượng hệ số tuyến tính mà dựa trên việc phân chia dữ liệu theo ngưỡng.

Việc giữ lại các biến dẫn xuất giúp mô hình học được các mối quan hệ phi tuyến và các ngưỡng lâm sàng quan trọng, thay vì loại bỏ thủ công dựa trên tương quan tuyến tính.
"""

numeric_features = [ # biến định lượng
    "age", "ap_hi", "ap_lo", "BMI",
    "pulse_pressure", "MAP"
]

binary_features = [ # biến nhị phân
    "smoke", "alco", "active",
    "hypertension", "metabolic_risk"
]

ordinal_features = [ # biến có thứ tự
    "cholesterol", "gluc", "BMI_class", "BP_class"
]

nominal_features = [ # biến phân loại, dùng để one hot
    "gender"
]

"""## Pipeline"""

from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder
from sklearn.impute import SimpleImputer

numeric_pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])

ordinal_pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("ordinal", OrdinalEncoder())
])

nominal_pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(drop="first", handle_unknown="ignore"))
])
preprocessor = ColumnTransformer([
    ("num", numeric_pipeline, numeric_features),
    ("ord", ordinal_pipeline, ordinal_features),
    ("nom", nominal_pipeline, nominal_features),
    ("bin", "passthrough", binary_features)
])

# Base
X_train_base.to_csv("X_train_base.csv", index=False)
X_test_base.to_csv("X_test_base.csv", index=False)
y_train.to_csv("y_train.csv", index=False)
y_test.to_csv("y_test.csv", index=False)

# FE
X_train_fe.to_csv("X_train_fe.csv", index=False)
X_test_fe.to_csv("X_test_fe.csv", index=False)